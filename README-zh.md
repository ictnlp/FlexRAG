<p align="center">
<img src="assets/flexrag-wide.png" width=55%>
</p>

![Language](https://img.shields.io/badge/language-python-brightgreen)
[![github license](https://img.shields.io/github/license/ictnlp/flexrag)](LICENSE)
[![Read the Docs](https://img.shields.io/readthedocs/flexrag)](https://flexrag.readthedocs.io/en/latest/)
[![PyPI - Version](https://img.shields.io/pypi/v/flexrag)](https://pypi.org/project/flexrag/)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.14593327.svg)](https://doi.org/10.5281/zenodo.14593327)

\[ [English](README.md) | [ä¸­æ–‡](README-zh.md) \]

FlexRAG æ˜¯ä¸€ä¸ªçµæ´»çš„é«˜æ€§èƒ½æ¡†æ¶ï¼Œä¸“ä¸ºæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ä»»åŠ¡è€Œè®¾è®¡ã€‚FlexRAG æ”¯æŒå¤šæ¨¡æ€æ•°æ®ï¼Œæä¾›ç»Ÿä¸€çš„é…ç½®ç®¡ç†åŠå¼€ç®±å³ç”¨çš„æ£€ç´¢ç³»ç»Ÿï¼Œä¸ºç§‘ç ”å’ŒåŸå‹è®¾è®¡æä¾›å……åˆ†æ”¯æŒã€‚

# ğŸ“– ç›®å½•
- [ğŸ“– ç›®å½•](#-ç›®å½•)
- [âœ¨ æ¡†æ¶ç‰¹è‰²](#-æ¡†æ¶ç‰¹è‰²)
- [ğŸ“¢ æœ€æ–°æ¶ˆæ¯](#-æœ€æ–°æ¶ˆæ¯)
- [ğŸš€ æ¡†æ¶å…¥é—¨](#-æ¡†æ¶å…¥é—¨)
  - [æ­¥éª¤0. å®‰è£…](#æ­¥éª¤0-å®‰è£…)
    - [`pip`å®‰è£…](#pipå®‰è£…)
    - [æºç å®‰è£…](#æºç å®‰è£…)
  - [æ­¥éª¤1. å‡†å¤‡æ£€ç´¢å™¨](#æ­¥éª¤1-å‡†å¤‡æ£€ç´¢å™¨)
    - [ä¸‹è½½çŸ¥è¯†åº“](#ä¸‹è½½çŸ¥è¯†åº“)
    - [æ„å»ºç´¢å¼•](#æ„å»ºç´¢å¼•)
  - [æ­¥éª¤2. è¿è¡Œ FlexRAG Assistant](#æ­¥éª¤2-è¿è¡Œ-flexrag-assistant)
    - [ä½¿ç”¨ GUI è¿è¡Œ Modular Assistant](#ä½¿ç”¨-gui-è¿è¡Œ-modular-assistant)
    - [åœ¨çŸ¥è¯†å¯†é›†å‹æ•°æ®é›†ä¸Šè¿è¡Œå¹¶æµ‹è¯• Modular Assistant](#åœ¨çŸ¥è¯†å¯†é›†å‹æ•°æ®é›†ä¸Šè¿è¡Œå¹¶æµ‹è¯•-modular-assistant)
    - [å¼€å‘æ‚¨è‡ªå·±çš„ RAG Assistant](#å¼€å‘æ‚¨è‡ªå·±çš„-rag-assistant)
    - [å¼€å‘æ‚¨è‡ªå·±çš„ RAG åº”ç”¨](#å¼€å‘æ‚¨è‡ªå·±çš„-rag-åº”ç”¨)
- [ğŸ—ï¸ FlexRAG æ¶æ„](#ï¸-flexrag-æ¶æ„)
- [ğŸ“Š åŸºå‡†æµ‹è¯•](#-åŸºå‡†æµ‹è¯•)
- [ğŸ·ï¸ è®¸å¯è¯](#ï¸-è®¸å¯è¯)
- [â¤ï¸ è‡´è°¢](#ï¸-è‡´è°¢)


# âœ¨ æ¡†æ¶ç‰¹è‰²
- **å¤šæ¨¡æ€RAG**: FlexRAG ä¸ä»…é™äºåŸºäºæ–‡æœ¬çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)ã€‚å®ƒè¿˜æ”¯æŒå¤šæ¨¡æ€ RAGï¼Œä¸ºä¸åŒæ•°æ®ç±»å‹å¼€è¾Ÿäº†å¹¿æ³›çš„åº”ç”¨å¯èƒ½æ€§ã€‚
- **å¤šæ•°æ®ç±»å‹**: FlexRAG æ”¯æŒå¤šç§æ•°æ®æ ¼å¼ï¼ŒåŒ…æ‹¬æ–‡æœ¬ï¼ˆä¾‹å¦‚ CSVã€JSONLï¼‰ã€å›¾åƒã€æ–‡æ¡£ã€Web å¿«ç…§ç­‰ï¼Œè®©æ‚¨å¯ä»¥çµæ´»åœ°å¤„ç†å„ç§æ•°æ®æºã€‚
- **ç»Ÿä¸€çš„é…ç½®ç®¡ç†**: åˆ©ç”¨ python `dataclass` å’Œ [hydra-core](https://github.com/facebookresearch/hydra), FlexRAG ç»Ÿä¸€äº†é…ç½®ç®¡ç†ï¼Œè®© RAG æµç¨‹çš„é…ç½®å˜å¾—æ›´åŠ ç®€å•ã€‚
- **å¼€ç®±å³ç”¨**: é€šè¿‡ç²¾å¿ƒä¼˜åŒ–çš„é»˜è®¤é…ç½®ï¼ŒFlexRAG åœ¨é»˜è®¤é…ç½®ä¸‹å°±æœ‰è‰¯å¥½çš„æ€§èƒ½ï¼Œç®€åŒ–æ‚¨çš„å¼€å‘æµç¨‹ã€‚
- **é«˜æ€§èƒ½**: åˆ©ç”¨æŒä¹…åŒ–ç¼“å­˜å’Œå¼‚æ­¥å‡½æ•°ï¼ŒFlexRAG æ˜¾è‘—æé«˜äº† RAG æµç¨‹çš„æ€§èƒ½ã€‚
- **ç§‘ç ”åŠå¼€å‘å‹å¥½**: æ”¯æŒå¤šç§å¼€å‘æ–¹å¼ã€‚æ­¤å¤–ï¼ŒFlexRAG æä¾›äº†ä¸€ä¸ªä¼´ç”Ÿä»“åº“ï¼Œ[flexrag_examples](https://github.com/ictnlp/flexrag_examples)ï¼Œæ¥å¸®åŠ©æ‚¨å¤ç°å„ç±»RAGç®—æ³•ã€‚
- **è½»é‡åŒ–**: FlexRAG é‡‡ç”¨æœ€å°‘çš„å¼€é”€è®¾è®¡ï¼Œé«˜æ•ˆä¸”æ˜“äºé›†æˆåˆ°æ‚¨çš„é¡¹ç›®ä¸­ã€‚

# ğŸ“¢ æœ€æ–°æ¶ˆæ¯
- **2025-01-05**: FlexRAG çš„[æ–‡æ¡£](https://flexrag.readthedocs.io/en/latest/)ç°å·²ä¸Šçº¿ã€‚

# ğŸš€ æ¡†æ¶å…¥é—¨

## æ­¥éª¤0. å®‰è£…

### `pip`å®‰è£…
ä» `pip` å®‰è£… FlexRAG:
```bash
pip install flexrag
```

### æºç å®‰è£…
æ­¤å¤–ï¼Œæ‚¨ä¹Ÿå¯ä»¥ä»æºç å®‰è£… FlexRAG:
```bash
pip install pybind11

git clone https://github.com/ictnlp/flexrag.git
cd flexrag
pip install ./
```
æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡ `-e` æ ‡å¿—åœ¨å¯ç¼–è¾‘æ¨¡å¼ä¸‹å®‰è£… FlexRAGã€‚


## æ­¥éª¤1. å‡†å¤‡æ£€ç´¢å™¨

### ä¸‹è½½çŸ¥è¯†åº“
åœ¨å¼€å§‹æ„å»ºæ‚¨çš„RAGåº”ç”¨ä¹‹å‰ï¼Œæ‚¨éœ€è¦å‡†å¤‡è¯­æ–™åº“ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[DPR](https://github.com/facebookresearch/DPR)æä¾›çš„ç»´åŸºç™¾ç§‘è¯­æ–™åº“ï¼Œæ‚¨å¯ä»¥é€šè¿‡å¦‚ä¸‹å‘½ä»¤æ¥ä¸‹è½½è¯­æ–™åº“ï¼š
```bash
# Download the corpus
wget https://dl.fbaipublicfiles.com/dpr/wikipedia_split/psgs_w100.tsv.gz
# Unzip the corpus
gzip -d psgs_w100.tsv.gz
```

### æ„å»ºç´¢å¼•
ä¸‹è½½è¯­æ–™åº“åï¼Œæ‚¨éœ€è¦ä¸ºæ£€ç´¢å™¨æ„å»ºç´¢å¼•ã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨å¯†é›†æ£€ç´¢å™¨ï¼Œæ‚¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥æ„å»ºç´¢å¼•ï¼š
```bash
CORPUS_PATH=psgs_w100.tsv.gz
CORPUS_FIELDS='[title,text]'
DB_PATH=<path_to_database>

python -m flexrag.entrypoints.prepare_index \
    corpus_path=$CORPUS_PATH \
    saving_fields=$CORPUS_FIELDS \
    retriever_type=dense \
    dense_config.database_path=$DB_PATH \
    dense_config.encode_fields='[text]' \
    dense_config.passage_encoder_config.encoder_type=hf \
    dense_config.passage_encoder_config.hf_config.model_path='facebook/contriever' \
    dense_config.passage_encoder_config.hf_config.device_id=[0,1,2,3] \
    dense_config.index_type=faiss \
    dense_config.faiss_config.batch_size=4096 \
    dense_config.faiss_config.log_interval=100000 \
    dense_config.batch_size=4096 \
    dense_config.log_interval=100000 \
    reinit=True
```

å¦‚æœæ‚¨æƒ³ä½¿ç”¨ç¨€ç–æ£€ç´¢å™¨ï¼Œæ‚¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥æ„å»ºç´¢å¼•ï¼š
```bash
CORPUS_PATH=psgs_w100.tsv.gz
CORPUS_FIELDS='[title,text]'
DB_PATH=<path_to_database>

python -m flexrag.entrypoints.prepare_index \
    corpus_path=$CORPUS_PATH \
    saving_fields=$CORPUS_FIELDS \
    retriever_type=bm25s \
    bm25s_config.database_path=$DB_PATH \
    bm25s_config.indexed_fields='[title,text]' \
    bm25s_config.method=lucene \
    bm25s_config.batch_size=512 \
    bm25s_config.log_interval=100000 \
    reinit=True
```

## æ­¥éª¤2. è¿è¡Œ FlexRAG Assistant
å½“ç´¢å¼•å‡†å¤‡å¥½åï¼Œæ‚¨å¯ä»¥è¿è¡Œ FlexRAG æ‰€æä¾›çš„ `Assistant` ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•è¿è¡Œ`Modular Assistant`çš„ç¤ºä¾‹ã€‚

### ä½¿ç”¨ GUI è¿è¡Œ Modular Assistant
```bash
python -m flexrag.entrypoints.run_interactive \
    assistant_type=modular \
    modular_config.used_fields=[title,text] \
    modular_config.retriever_type=dense \
    modular_config.dense_config.top_k=5 \
    modular_config.dense_config.database_path=${DB_PATH} \
    modular_config.dense_config.query_encoder_config.encoder_type=hf \
    modular_config.dense_config.query_encoder_config.hf_config.model_path='facebook/contriever' \
    modular_config.dense_config.query_encoder_config.hf_config.device_id=[0] \
    modular_config.response_type=short \
    modular_config.generator_type=openai \
    modular_config.openai_config.model_name='gpt-4o-mini' \
    modular_config.openai_config.api_key=$OPENAI_KEY \
    modular_config.do_sample=False
```

### åœ¨çŸ¥è¯†å¯†é›†å‹æ•°æ®é›†ä¸Šè¿è¡Œå¹¶æµ‹è¯• Modular Assistant
æ‚¨å¯ä»¥åœ¨å¤šä¸ªçŸ¥è¯†å¯†é›†å‹æ•°æ®é›†ä¸Šè½»æ¾è¯„ä¼°æ‚¨çš„ RAG Assistant ã€‚ä»¥ä¸‹å‘½ä»¤è®©æ‚¨å¯ä»¥åœ¨ Natural Questions (NQ) æ•°æ®é›†ä¸Šè¯„ä¼°é‡‡ç”¨ç¨ å¯†æ£€ç´¢å™¨çš„`modular assistant`ï¼š
```bash
OUTPUT_PATH=<path_to_output>
DB_PATH=<path_to_database>
OPENAI_KEY=<your_openai_key>

python -m flexrag.entrypoints.run_assistant \
    data_path=flash_rag/nq/test.jsonl \
    output_path=${OUTPUT_PATH} \
    assistant_type=modular \
    modular_config.used_fields=[title,text] \
    modular_config.retriever_type=dense \
    modular_config.dense_config.top_k=10 \
    modular_config.dense_config.database_path=${DB_PATH} \
    modular_config.dense_config.query_encoder_config.encoder_type=hf \
    modular_config.dense_config.query_encoder_config.hf_config.model_path='facebook/contriever' \
    modular_config.dense_config.query_encoder_config.hf_config.device_id=[0] \
    modular_config.response_type=short \
    modular_config.generator_type=openai \
    modular_config.openai_config.model_name='gpt-4o-mini' \
    modular_config.openai_config.api_key=$OPENAI_KEY \
    modular_config.do_sample=False \
    eval_config.metrics_type=[retrieval_success_rate,generation_f1,generation_em] \
    eval_config.retrieval_success_rate_config.context_preprocess.processor_type=[simplify_answer] \
    eval_config.retrieval_success_rate_config.eval_field=text \
    eval_config.response_preprocess.processor_type=[simplify_answer] \
    log_interval=10
```

ç›¸ä¼¼åœ°ï¼Œæ‚¨å¯ä»¥åœ¨ Natural Questions æ•°æ®é›†ä¸Šè¯„ä¼°é‡‡ç”¨ç¨€ç–æ£€ç´¢å™¨çš„`modular assistant`ï¼š
```bash
OUTPUT_PATH=<path_to_output>
DB_PATH=<path_to_database>
OPENAI_KEY=<your_openai_key>

python -m flexrag.entrypoints.run_assistant \
    data_path=flash_rag/nq/test.jsonl \
    output_path=${OUTPUT_PATH} \
    assistant_type=modular \
    modular_config.used_fields=[title,text] \
    modular_config.retriever_type=bm25s \
    modular_config.bm25s_config.top_k=10 \
    modular_config.bm25s_config.database_path=${DB_PATH} \
    modular_config.response_type=short \
    modular_config.generator_type=openai \
    modular_config.openai_config.model_name='gpt-4o-mini' \
    modular_config.openai_config.api_key=$OPENAI_KEY \
    modular_config.do_sample=False \
    eval_config.metrics_type=[retrieval_success_rate,generation_f1,generation_em] \
    eval_config.retrieval_success_rate_config.context_preprocess.processor_type=[simplify_answer] \
    eval_config.retrieval_success_rate_config.eval_field=text \
    eval_config.response_preprocess.processor_type=[simplify_answer] \
    log_interval=10
```

æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡åœ¨å‘½ä»¤è¡Œä¸­æ·»åŠ  `user_module=<your_module_path>` å‚æ•°æ¥è¯„ä¼°æ‚¨è‡ªå·±çš„åŠ©æ‰‹ã€‚

### å¼€å‘æ‚¨è‡ªå·±çš„ RAG Assistant
æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡å¯¼å…¥æ‰€éœ€çš„ FlexRAG æ¨¡å—æ¥åˆ›å»ºæ‚¨è‡ªå·±çš„ RAG Assistantã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•æ„å»º RAG Assistant çš„ç¤ºä¾‹ï¼š
```python
from dataclasses import dataclass

from flexrag.assistant import ASSISTANTS, AssistantBase
from flexrag.models import OpenAIGenerator, OpenAIGeneratorConfig
from flexrag.prompt import ChatPrompt, ChatTurn
from flexrag.retriever import DenseRetriever, DenseRetrieverConfig


@dataclass
class SimpleAssistantConfig(DenseRetrieverConfig, OpenAIGeneratorConfig): ...


@ASSISTANTS("simple", config_class=SimpleAssistantConfig)
class SimpleAssistant(AssistantBase):
    def __init__(self, config: SimpleAssistantConfig):
        self.retriever = DenseRetriever(config)
        self.generator = OpenAIGenerator(config)
        return

    def answer(self, question: str) -> str:
        prompt = ChatPrompt()
        context = self.retriever.search(question)[0]
        prompt_str = ""
        for ctx in context:
            prompt_str += f"Question: {question}\nContext: {ctx.data['text']}"
        prompt.update(ChatTurn(role="user", content=prompt_str))
        response = self.generator.chat([prompt])[0][0]
        prompt.update(ChatTurn(role="assistant", content=response))
        return response
```
åœ¨å®Œæˆ`SimpleAssistant`å®šä¹‰å¹¶ä½¿ç”¨`ASSISTANTS`è£…é¥°å™¨æ³¨å†Œè¯¥ Assistant åï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ¥è¿è¡Œæ‚¨çš„ Assistantï¼š
```bash
DB_PATH=<path_to_database>
OPENAI_KEY=<your_openai_key>
DATA_PATH=<path_to_data>
MODULE_PATH=<path_to_simple_assistant_module>

python -m flexrag.entrypoints.run_assistant \
    user_module=${MODULE_PATH} \
    data_path=${DATA_PATH} \
    assistant_type=simple \
    simple_config.model_name='gpt-4o-mini' \
    simple_config.api_key=${OPENAI_KEY} \
    simple_config.database_path=${DB_PATH} \
    simple_config.index_type=faiss \
    simple_config.query_encoder_config.encoder_type=hf \
    simple_config.query_encoder_config.hf_config.model_path='facebook/contriever' \
    simple_config.query_encoder_config.hf_config.device_id=[0] \
    eval_config.metrics_type=[retrieval_success_rate,generation_f1,generation_em] \
    eval_config.retrieval_success_rate_config.eval_field=text \
    eval_config.response_preprocess.processor_type=[simplify_answer] \
    log_interval=10
```
åœ¨ [flexrag_examples](https://github.com/ictnlp/flexrag_examples) ä»“åº“ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿæä¾›äº†ä¸€äº›ç¤ºä¾‹ï¼Œè¯¦ç»†å±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨ FlexRAG æ¡†æ¶æ„å»º RAG åŠ©æ‰‹ã€‚

### å¼€å‘æ‚¨è‡ªå·±çš„ RAG åº”ç”¨
é™¤äº†ç›´æ¥ä½¿ç”¨ FlexRAG å†…ç½®çš„ Entrypoints æ¥è¿è¡Œæ‚¨çš„ RAG Assistant ä»¥å¤–ï¼Œæ‚¨ä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨ FlexRAG æ„å»ºæ‚¨è‡ªå·±çš„ RAG åº”ç”¨ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•æ„å»º RAG åº”ç”¨çš„ç¤ºä¾‹ï¼š
```python
from flexrag.models import HFEncoderConfig, OpenAIGenerator, OpenAIGeneratorConfig
from flexrag.prompt import ChatPrompt, ChatTurn
from flexrag.retriever import DenseRetriever, DenseRetrieverConfig


def main():
    # Initialize the retriever
    retriever_cfg = DenseRetrieverConfig(database_path="path_to_database", top_k=1)
    retriever_cfg.query_encoder_config.encoder_type = "hf"
    retriever_cfg.query_encoder_config.hf_config = HFEncoderConfig(
        model_path="facebook/contriever"
    )
    retriever = DenseRetriever(retriever_cfg)

    # Initialize the generator
    generator = OpenAIGenerator(
        OpenAIGeneratorConfig(
            model_name="gpt-4o-mini", api_key="your_openai_key", do_sample=False
        )
    )

    # Run your RAG application
    prompt = ChatPrompt()
    while True:
        query = input("Please input your query (type `exit` to exit): ")
        if query == "exit":
            break
        context = retriever.search(query)[0]
        prompt_str = ""
        for ctx in context:
            prompt_str += f"Question: {query}\nContext: {ctx.data['text']}"
        prompt.update(ChatTurn(role="user", content=prompt_str))
        response = generator.chat(prompt)
        prompt.update(ChatTurn(role="assistant", content=response))
        print(response)
    return


if __name__ == "__main__":
    main()
```
æ›´å¤šä½¿ç”¨ FlexRAG æ„å»º RAG åº”ç”¨çš„ç¤ºä¾‹ï¼Œè¯·å‚è€ƒ [flexrag_examples](https://github.com/ictnlp/flexrag_examples) ä»“åº“ã€‚


# ğŸ—ï¸ FlexRAG æ¶æ„
FlexRAG é‡‡ç”¨**æ¨¡å—åŒ–**æ¶æ„è®¾è®¡ï¼Œè®©æ‚¨å¯ä»¥è½»æ¾å®šåˆ¶å’Œæ‰©å±•æ¡†æ¶ä»¥æ»¡è¶³æ‚¨çš„ç‰¹å®šéœ€æ±‚ã€‚ä¸‹å›¾è¯´æ˜äº† FlexRAG çš„æ¶æ„ï¼š
<p align="center">
<img src="assets/Framework-Librarian-v2.png" width=70%>
</p>

# ğŸ“Š åŸºå‡†æµ‹è¯•
æˆ‘ä»¬åˆ©ç”¨ FlexRAG è¿›è¡Œäº†å¤§é‡çš„åŸºå‡†æµ‹è¯•ï¼Œè¯¦æƒ…è¯·å‚è€ƒ [benchmarks](benchmarks.md) é¡µé¢ã€‚

# ğŸ·ï¸ è®¸å¯è¯
æœ¬ä»“åº“é‡‡ç”¨ **MIT License** å¼€æºåè®®. è¯¦æƒ…è¯·å‚è€ƒ [LICENSE](LICENSE) æ–‡ä»¶ã€‚


<!-- # ğŸ–‹ï¸ å¼•ç”¨
å¦‚æœæ‚¨è§‰å¾— FlexRAG å¯¹æ‚¨çš„ç ”ç©¶æœ‰æ‰€å¸®åŠ©ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„å·¥ä½œ:

```bibtex
@software{FlexRAG,
  author = {Zhang Zhuocheng},
  doi = {10.5281/zenodo.14306984},
  month = {12},
  title = {{FlexRAG}},
  url = {https://github.com/ictnlp/flexrag},
  version = {0.1.0},
  year = {2024}
}
``` -->

# â¤ï¸ è‡´è°¢
ä¸‹é¢çš„å¼€æºé¡¹ç›®å¯¹æœ¬é¡¹ç›®æœ‰æ‰€å¸®åŠ©:
- [Faiss](https://github.com/facebookresearch/faiss)
- [FlashRAG](https://github.com/RUC-NLPIR/FlashRAG)
- [LanceDB](https://github.com/lancedb/lancedb)
- [ANN Benchmarks](https://github.com/erikbern/ann-benchmarks)
- [Chonkie](https://github.com/chonkie-ai/chonkie)
- [rerankers](https://github.com/AnswerDotAI/rerankers)
